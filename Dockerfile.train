# This is a Dockerfile useful for training models with Coqui STT.
# You can train "acoustic models" with audio + Tensorflow, and
# you can create "scorers" with text + KenLM.

FROM ghcr.io/reuben/manylinux_2_24:2022-03-31-361e6b6 as py-venv
ENV VIRTUAL_ENV=/venv
ENV PATH="$VIRTUAL_ENV/bin:$PATH"
RUN /opt/python/cp38*/bin/python -m venv $VIRTUAL_ENV && \
    $VIRTUAL_ENV/bin/pip install --upgrade pip wheel setuptools

# Create Python 3.7 virtualenv for installing upstream TF package with TFLite
RUN /opt/python/cp37*/bin/python -m venv /tflite-venv && \
    /tflite-venv/bin/pip install --upgrade pip wheel setuptools

FROM py-venv AS gen-scorer-package-build
COPY native_client /code/native_client
COPY tensorflow /code/tensorflow
COPY ci_scripts /code/ci_scripts
WORKDIR /code
RUN ./ci_scripts/tf-setup.sh && \
    ./ci_scripts/gen-scorer-package-build.sh && \
    cp tensorflow/bazel-bin/native_client/generate_scorer_package . && \
    cd tensorflow && /code/bin/bazel clean && rm -rf /code/bin /code/dls

FROM ghcr.io/reuben/manylinux_2_24:2022-03-31-361e6b6 AS kenlm-build
RUN apt-get update && \
    DEBIAN_FRONTEND=noninteractive \
    apt-get install -y --no-install-recommends \
        build-essential cmake libboost-system-dev \
        libboost-thread-dev libboost-program-options-dev \
        libboost-test-dev libeigen3-dev zlib1g-dev \
        libbz2-dev liblzma-dev && \
    rm -rf /var/lib/apt/lists/*

# Build KenLM to generate new scorers
COPY kenlm /code/kenlm
RUN mkdir -p /code/kenlm/build && \
    cd /code/kenlm/build && \
    cmake .. && \
    make -j $(nproc) || \
    ( \
        echo "ERROR: Failed to build KenLM." \
        echo "ERROR: Make sure you update the kenlm submodule on host before building this Dockerfile." \
        echo "ERROR: $ cd STT; git submodule update --init kenlm" \
        exit 1 \
    )

FROM py-venv as decoder-build
COPY native_client /code/native_client
COPY training/coqui_stt_training/VERSION /code/training/coqui_stt_training/VERSION
COPY VERSION /code/VERSION
COPY training/coqui_stt_training/GRAPH_VERSION /code/training/coqui_stt_training/GRAPH_VERSION
COPY GRAPH_VERSION /code/GRAPH_VERSION
COPY native_client/ctcdecode/workspace_status.cc /code/native_client/ctcdecode/workspace_status.cc

# Build CTC decoder first, to avoid clashes on incompatible versions upgrades
WORKDIR /code
RUN make -C native_client/ctcdecode bindings NUM_PROCESSES=$(nproc) && \
    cp native_client/ctcdecode/dist/*.whl . && \
    make -C native_client/ctcdecode clean

FROM nvcr.io/nvidia/tensorflow:22.02-tf1-py3
COPY --from=decoder-build /code/*.whl /code
COPY --from=kenlm-build /code/kenlm-bin /code/kenlm/build/bin
COPY --from=gen-scorer-package-build /code/generate_scorer_package /code
COPY setup.py /code/setup.py
COPY VERSION /code/VERSION
COPY GRAPH_VERSION /code/GRAPH_VERSION
COPY training /code/training

# Install STT
# Use decoder wheel from previous stage
# TensorFlow GPU should already be installed on the base image,
# and we don't want to break that
WORKDIR /code
RUN apt-get update && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends libboost-program-options1.71.0 libboost-thread1.71.0 && \
    rm -rf /var/lib/apt/lists/* && \
    pip install --upgrade coqui_stt_ctcdecoder-*.whl && \
    DS_NODECODER=y DS_NOTENSORFLOW=y pip install --upgrade -e

# Install coqui_stt_training (inside tf-venv) for exporting models using tflite
RUN /tflite-venv/bin/pip install -e .

# Copy rest of the code and test training
COPY . /code
RUN ./bin/run-ldc93s1.sh && rm -rf ~/.local/share/stt
